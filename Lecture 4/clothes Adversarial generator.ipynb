{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import h5py\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tensorflow.python.keras.optimizers import Adam,RMSprop \n",
    "\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras.preprocessing import image\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.models import Sequential,model_from_json\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "STARTDIR='C:\\\\data\\\\clothes\\\\'\n",
    "adversarialexample_dir = os.path.join(STARTDIR,'adversarialexample\\\\')\n",
    "model_dir = os.path.join(STARTDIR,'model_ourclothes.json')\n",
    "weights_dir=os.path.join(STARTDIR,'weights_ourclothes.h5')\n",
    "image_width, image_height = 150, 150\n",
    "learning_rate = 0.2 ## How much to update the hacked image in each iteration\n",
    "object_type_to_fake = 1  #Pant\n",
    "input_shape = (image_width, image_height, 3) \n",
    "labels = ['hat', 'pant', 'shirt', 'shoes', 'skirt', 'socks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file = open(model_dir, 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "loaded_model.load_weights(weights_dir)\n",
    "#print(loaded_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_input_layer = loaded_model.layers[0].input  # First Layer\n",
    "model_output_layer = loaded_model.layers[-1].output # Last Layer    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(adversarialexample_dir)\n",
    "    \n",
    "for file in files:\n",
    "        fullFileName= os.path.join(adversarialexample_dir, file)\n",
    "        print(fullFileName)\n",
    "         \n",
    "        img = image.load_img(fullFileName, target_size=(image_width, image_height))\n",
    "        original_image = image.img_to_array(img)\n",
    "\n",
    "   \n",
    "        original_image /= 255.\n",
    "\n",
    "        # Add a 4th dimension for batch size (as Keras expects)\n",
    "        original_image = np.expand_dims(original_image, axis=0)\n",
    "        #Create a copy of the input image to hack on\n",
    "        adversarialEg_image = np.copy(original_image)\n",
    "        \n",
    "        # Pre-calculate the maximum change we will allow to the image\n",
    "        max_change_above = original_image + 0.01\n",
    "        max_change_below = original_image - 0.01\n",
    "\n",
    "        # Define the cost function.\n",
    "        # Our 'cost' will be the likelihood out image is the target class according to the pre-trained model\n",
    "        cost_function = model_output_layer[0, object_type_to_fake]\n",
    "\n",
    "        # We'll ask Keras to calculate the gradient based on the input image and the currently predicted class\n",
    "        # In this case, referring to \"model_input_layer\" will give us back image we are hacking.\n",
    "        gradient_function = K.gradients(cost_function, model_input_layer)[0]\n",
    "\n",
    "        # Create a Keras function that we can call to calculate the current cost and gradient\n",
    "        grab_cost_and_gradients_from_model = K.function([model_input_layer, K.learning_phase()], [cost_function, gradient_function])\n",
    "\n",
    "        cost = 0.0     \n",
    "        \n",
    "        # In a loop, keep adjusting the adversarialEg image slightly so that it tricks the model more and more\n",
    "        # until it gets to at least 90% confidence\n",
    "        while cost < 0.85:\n",
    "            # Check how close the image is to our target class and grab the gradients we\n",
    "            # can use to push it one more step in that direction.\n",
    "            # Note: It's really important to pass in '0' for the Keras learning mode here!\n",
    "            # Keras layers behave differently in prediction vs. train modes!\n",
    "            cost, gradients = grab_cost_and_gradients_from_model([adversarialEg_image, 0])\n",
    "\n",
    "            # Move the adversarialEg image one step further towards fooling the model\n",
    "            adversarialEg_image += gradients * learning_rate\n",
    "\n",
    "            # Ensure that the image doesn't ever change too much to either look funny or to become an invalid image\n",
    "            adversarialEg_image = np.clip(adversarialEg_image, max_change_below, max_change_above)\n",
    "            adversarialEg_image = np.clip(adversarialEg_image, -1.0, 1.0)\n",
    "\n",
    "            print(\"Adversarial Example Image cost is {:.3}%\".format(cost * 100))\n",
    "\n",
    "        # De-scale the image's pixels from [-1, 1] back to the [0, 255] range\n",
    "        img = adversarialEg_image[0]\n",
    "        img *= 255.\n",
    "        # Save the adversarialEg image!\n",
    "        im = Image.fromarray(img.astype(np.uint8))\n",
    "        file = \"advEx_\"+file\n",
    "        adversarialEgFileName= os.path.join(adversarialexample_dir, file)\n",
    "        print(adversarialEgFileName)\n",
    "        im.save(adversarialEgFileName)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
